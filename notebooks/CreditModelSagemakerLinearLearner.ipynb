{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/pmservice/ai-openscale-tutorials/raw/master/notebooks/images/banner.png\" align=\"left\" alt=\"banner\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitor Sagemaker ML With Watson OpenScale\n",
    "\n",
    "In this notebook, we will use a German Credit dataset to create a logistic regression model using AWS SageMaker. We'll prepare the data and store it in AWS S3, create the model, and deploy the model to the AWS cloud. We'll then score the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contents\n",
    " - [1.0 Setup](#setup)\n",
    " - [2.0 Load and explore data](#load)\n",
    " - [3.0 Create logistic regression model using SageMaker linear-learner algorithm](#model)\n",
    " - [4.0 Deploy the SageMaker model in the AWS Cloud](#deploy)\n",
    " - [5.0 Score the model](#score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This notebook works correctly with kernel `Python 3.7.x`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Setup<a id=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
    "\n",
    "- [Create an AWS SageMaker Service](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-set-up.html), and [get the AWS keys](https://github.com/IBM/monitor-sagemaker-ml-with-watson-openscale#get-aws-keys)\n",
    "- Install reqiured python packages from PyPi repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U boto3 | tail -n 1\n",
    "!pip install -U sagemaker | tail -n 1\n",
    "!pip install -U pandas==1.2.5 | tail -n 1\n",
    "!pip install -U scikit_learn==0.20.3 | tail -n 1\n",
    "!pip install -U category_encoders | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restart the kernel now to ensure the recently installed packages are used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Load and explore data<a id=\"load\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will prepare your data for training using SageMaker linear-learner algorithm.\n",
    "\n",
    "- Load data from github repository\n",
    "- Explore data\n",
    "- Prepare training data\n",
    "- Store training data in S3 Object Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load data from github repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/IBM/monitor-sagemaker-ml-with-watson-openscale/master/data/credit_risk_training.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sample records:\")\n",
    "display(data.head())\n",
    "\n",
    "print(\"Label column summary:\")\n",
    "display(data.Risk.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Prepare training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use SageMaker build-in linear-learner algorithm. This algorithm expects first column to be the label when training data is in `text/csv` format.\n",
    "\n",
    "Moreover label column have to be numeric, so you will recode it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Risk'\n",
    "string_features = [nm for nm, ty in zip(data.dtypes.index, data.dtypes.values) if (nm != target) and (ty is np.dtype('O')) ]\n",
    "numeric_features = [nm for nm, ty in zip(data.dtypes.index, data.dtypes.values) if (nm != target) and (ty is not np.dtype('O'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_recoded = pd.concat([data[[target]], pd.get_dummies(data[string_features]), data[numeric_features]], axis=1)\n",
    "data_recoded.replace({target: {'Risk': 1, 'No Risk': 0}}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_filename = 'credit_risk_training_recoded.csv'\n",
    "data_recoded.to_csv(path_or_buf = train_data_filename, index = False, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Header row have to be omitted. First column have to be target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_recoded.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Store training data in S3 Object Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import boto3\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 Add AWS credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_credentials = {'access_key': '***', \n",
    "                   'secret_key': '***', \n",
    "                   'region_name': '***'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "session = boto3.session.Session(\n",
    "    aws_access_key_id = aws_credentials['access_key'],\n",
    "    aws_secret_access_key = aws_credentials['secret_key'],\n",
    "    region_name = aws_credentials['region_name']\n",
    ")\n",
    "region = session.region_name\n",
    "sagemaker_session = sagemaker.Session(session)\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "s3 = session.resource('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 Get bucket name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Default bucket: {}'.format(bucket))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Tip:** You can run following code `[bkt.name for bkt in s3.buckets.all()]` to list all your buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[bkt.name for bkt in s3.buckets.all()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 Replace `bucket_name` with name of bucket in your S3 Object Storage and path where training data will be stored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = '*******'\n",
    "train_data_path = 'credit_risk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data_path = 's3://{}/credit-risk/output'.format(bucket_name)\n",
    "time_suffix = time.strftime(\"%Y-%m-%d-%H-%M\", time.gmtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = s3.Bucket(bucket_name)\n",
    "s3_bucket.upload_file(Filename = train_data_filename, Key = '{}/{}'.format(train_data_path, train_data_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if your data have been uploaded successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s3_obj in s3_bucket.objects.all():\n",
    "    if (s3_obj.bucket_name == bucket_name) and (train_data_path in s3_obj.key):\n",
    "        train_data_uri = 's3://{}/{}'.format(s3_obj.bucket_name, s3_obj.key)\n",
    "        print(train_data_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>\n",
    "## 3.0 Create logistic regression model using SageMaker linear-learner algorithm\n",
    "\n",
    "In this section you will learn how to:\n",
    "\n",
    "- Setup training parameters\n",
    "- Start training job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "sm_client = session.client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image = get_image_uri(session.region_name, 'linear-learner')\n",
    "\n",
    "iam_client = session.client('iam')\n",
    "[role_arn, *_] = [role['Arn'] for role in iam_client.list_roles()['Roles'] if 'AmazonSageMaker-ExecutionRole' in role['RoleName'] or  'SagemakerFull' in role['RoleName']]\n",
    "\n",
    "linear_job_name = 'Credit-risk-linear-learner-' + time_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_training_params = {\n",
    "    \"AlgorithmSpecification\": {\n",
    "        \"TrainingImage\": training_image,\n",
    "        \"TrainingInputMode\": \"File\"\n",
    "    },\n",
    "    \"HyperParameters\": {\n",
    "        \"feature_dim\": str(data_recoded.shape[1] - 1),\n",
    "        \"mini_batch_size\": \"100\",\n",
    "        \"predictor_type\": \"binary_classifier\",\n",
    "        \"epochs\": \"10\",\n",
    "        \"num_models\": \"32\",\n",
    "        \"loss\": \"auto\"\n",
    "    },\n",
    "    \"InputDataConfig\": [{\n",
    "        \"ChannelName\": \"train\",\n",
    "        \"ContentType\": \"text/csv\", \n",
    "        \"DataSource\": {\n",
    "            \"S3DataSource\": {\n",
    "                \"S3DataType\": \"S3Prefix\",\n",
    "                \"S3Uri\": train_data_uri,\n",
    "                \"S3DataDistributionType\": \"ShardedByS3Key\"\n",
    "            }\n",
    "        }\n",
    "    }],\n",
    "    \"OutputDataConfig\": {\"S3OutputPath\": output_data_path},\n",
    "    \"ResourceConfig\": {\n",
    "        \"InstanceCount\": 1,\n",
    "        \"InstanceType\": \"ml.c4.xlarge\",\n",
    "        \"VolumeSizeInGB\": 2\n",
    "    },\n",
    "    \"RoleArn\": role_arn,\n",
    "    \"StoppingCondition\": {\n",
    "        \"MaxRuntimeInSeconds\": 6 * 60\n",
    "    },\n",
    "    \"TrainingJobName\": linear_job_name\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.create_training_job(**linear_training_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sm_client.get_waiter('training_job_completed_or_stopped').wait(TrainingJobName = linear_job_name)\n",
    "except Exception:\n",
    "    print('Traing job error.')\n",
    "\n",
    "train_job_details = sm_client.describe_training_job(TrainingJobName = linear_job_name)\n",
    "train_job_status = train_job_details['TrainingJobStatus']\n",
    "\n",
    "if train_job_status == 'Failed':\n",
    "    print(train_job_details['FailureReason'])\n",
    "else:\n",
    "    train_job_arn = train_job_details['TrainingJobArn']\n",
    "    print(train_job_arn)\n",
    "    trained_model_uri = train_job_details['ModelArtifacts']['S3ModelArtifacts']\n",
    "    print(trained_model_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Deploy the SageMaker model in the AWS Cloud <a id=\"deploy\"></a>\n",
    "\n",
    "In this section you will learn howto:\n",
    "\n",
    "- Setup deployment parameters\n",
    "- Create deployment configuration endpoint\n",
    "- Create online scoring endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Setup deployment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_hosting_container = {'Image': training_image, 'ModelDataUrl': trained_model_uri}\n",
    "\n",
    "create_model_details = sm_client.create_model(\n",
    "    ModelName = linear_job_name,\n",
    "    ExecutionRoleArn = role_arn,\n",
    "    PrimaryContainer = linear_hosting_container)\n",
    "\n",
    "print(create_model_details['ModelArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Create deployment configuration endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config = 'Credit-risk-linear-endpoint-config-' + time_suffix\n",
    "print(endpoint_config)\n",
    "\n",
    "create_endpoint_config_details = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config,\n",
    "    ProductionVariants = [{\n",
    "        'InstanceType': 'ml.m4.xlarge',\n",
    "        'InitialInstanceCount': 1,\n",
    "        'ModelName': linear_job_name,\n",
    "        'VariantName': 'AllTraffic'}])\n",
    "\n",
    "endpoint_config_details = sm_client.describe_endpoint_config(EndpointConfigName = endpoint_config)\n",
    "print(endpoint_config_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Create online scoring endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_endpoint = 'Credit-risk-endpoint-scoring-' + time_suffix\n",
    "\n",
    "create_endpoint_details = sm_client.create_endpoint(\n",
    "    EndpointName = scoring_endpoint,\n",
    "    EndpointConfigName = endpoint_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sm_client.get_waiter('endpoint_in_service').wait(EndpointName = scoring_endpoint)\n",
    "except Exception:\n",
    "    print('Create scoring endpoint error')\n",
    "\n",
    "scoring_endpoint_details = sm_client.describe_endpoint(EndpointName = scoring_endpoint)\n",
    "scoring_enpoint_config_status = scoring_endpoint_details['EndpointStatus']\n",
    "\n",
    "if scoring_enpoint_config_status != 'InService':\n",
    "    print(scoring_endpoint_details['FailureReason'])\n",
    "else:\n",
    "    print(scoring_endpoint_details['EndpointArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Score the model <a id=\"score\"></a>\n",
    "\n",
    "In this section you will learn howto score deployed model.\n",
    "\n",
    "- Prepare sample data for scoring\n",
    "- Send payload for scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Prepare sample data for scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use data in `csv` format as scoring payload. First column (label) is removed from data. Last 20 training records are selected as scoring payload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_data_filename = 'credit_risk_scoring_recoded.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_data_filename) as f_train:\n",
    "    with open(scoring_data_filename, 'w') as f_score:\n",
    "        f_score.writelines([','.join(line.split(',')[1:]) for line in f_train.readlines()[-10:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Send payload for scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_runtime = session.client('runtime.sagemaker')\n",
    "\n",
    "with open(scoring_data_filename) as f_payload:\n",
    "    scoring_response = sm_runtime.invoke_endpoint(EndpointName = scoring_endpoint,\n",
    "                                                  ContentType = 'text/csv',\n",
    "                                                  Body = f_payload.read().encode())\n",
    "    \n",
    "    scored_records = scoring_response['Body'].read().decode()\n",
    "    print(json.loads(scored_records))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
